#include "bang.h"
#include "cnrt.h"
const int NRAM_MAX_SIZE = 1024 * 256;
__nram__ char nram_buffer[NRAM_MAX_SIZE];

template<typename T>
__mlu_global__ void softmaxKernelAxis_e(T *destination, T const *source, int othersize, int dimsize, int dimS) {// axis = -1
  
  const int SRC_MAX_SIZE = NRAM_MAX_SIZE / 8;
  const int wSize = 128 / sizeof(T);
  
  const int maxNum = SRC_MAX_SIZE/sizeof(T);
  __nram__ T srcMax[2];
  if(dimsize >= maxNum){
    T *src = (T *)nram_buffer;
    T *destSum = src + 3 * maxNum;
    T *destSumFinal = destSum + maxNum;
    T destOldMax;
    T destNewMax;

    int remain = dimsize % maxNum;
    int repeat = (dimsize - remain)/maxNum;

    int otherRemain = othersize % taskDim;
    int stepEasy = (othersize - otherRemain) / taskDim;
    int stepHard = stepEasy + 1;
    int step = (taskId < otherRemain ? stepHard : stepEasy);
    int startHard = taskId * stepHard;
    int startEasy = otherRemain * stepHard + (taskId - otherRemain) * stepEasy;
    int indStart = (taskId < otherRemain ? startHard : startEasy);
    source = source + indStart * dimsize;
    destination = destination + indStart * dimsize;
    
    for(int s = 0; s < step; s++){
      
      destOldMax = -INFINITY;
      destNewMax = -INFINITY;
      __bang_write_zero(destSum, maxNum);
      for(int i = 0; i < repeat + 1; i++){
        if(i < repeat){
          __memcpy_async(src + i % 2 * maxNum, source + s * dimsize + i * maxNum, maxNum * sizeof(T), GDRAM2NRAM);
        }
        if(i > 0){
          __bang_argmax(srcMax, src + (i - 1) % 2 * maxNum, maxNum);
          if(destNewMax < srcMax[0]){
            destNewMax = srcMax[0];
          }
          __bang_sub_scalar(src + (i - 1) % 2 * maxNum, src + (i - 1) % 2 * maxNum, destNewMax, maxNum);
          __bang_active_exp_less_0(src + (i - 1) % 2 * maxNum, src + (i - 1) % 2 * maxNum, maxNum);
          if(i > 1){
            __bang_mul_scalar(destSum, destSum, exp(destOldMax - destNewMax), maxNum);
          }
          __bang_add(destSum, destSum, src + (i - 1) % 2 * maxNum, maxNum);
          destOldMax = destNewMax;
        }
        __sync_all_ipu();
      }
      //------------
      if(remain){
        __bang_write_value(src, maxNum, -INFINITY);
        __memcpy(src, source + s * dimsize + repeat * maxNum, remain * sizeof(T), GDRAM2NRAM);
        
        __bang_argmax(srcMax, src, maxNum);
        if(destNewMax < srcMax[0]){
          destNewMax = srcMax[0];
        }
        
        __bang_sub_scalar(src, src, destNewMax, maxNum);
        __bang_active_exp_less_0(src, src, maxNum);
        if(repeat > 0){
          __bang_mul_scalar(destSum, destSum, exp(destOldMax - destNewMax), maxNum);
        }
        __bang_add(destSum, destSum, src, maxNum);
        destOldMax = destNewMax;
      }
      //--------------
      //--------------------------------
      
      int segNum = maxNum / wSize;
      for(int strip = segNum/2; strip > 0; strip = strip / 2){
        for(int i = 0; i < strip ; i++){
          __bang_add(destSum + i * wSize, destSum + i * wSize, destSum + (i + strip) * wSize, wSize);
        } 
      }
      __bang_reduce_sum(destSumFinal, destSum, wSize);
      
      //-----------
      T globalSumInv = 1.0/destSumFinal[0];
      for(int i = 0; i < repeat + 2; i++){
        if(i < repeat){
          __memcpy_async(src + i % 3 * maxNum, source + s * dimsize + i * maxNum, maxNum * sizeof(T), GDRAM2NRAM);
        }
        if(i > 0 && i < repeat + 1){
          __bang_sub_scalar(src + (i - 1) % 3 * maxNum, src + (i - 1) % 3 * maxNum, destNewMax, maxNum); 
          __bang_active_exp_less_0(src + (i - 1) % 3 * maxNum, src + (i - 1) % 3 * maxNum, maxNum);
          __bang_mul_scalar(src + (i - 1) % 3 * maxNum, src + (i - 1) % 3 * maxNum, globalSumInv, maxNum);
        }
        if(i > 1){
          __memcpy_async(destination + s * dimsize + (i - 2) * maxNum, src + (i - 2) % 3 * maxNum, maxNum * sizeof(T), NRAM2GDRAM);
        }
        __sync_all_ipu();
        
      }
      if(remain){
        __bang_write_value(src, maxNum, destNewMax);
        __memcpy(src, source + s * dimsize + repeat * maxNum, remain * sizeof(T), GDRAM2NRAM);
        __bang_sub_scalar(src, src, destNewMax, maxNum);
        __bang_active_exp_less_0(src, src, maxNum);
        __bang_mul_scalar(src, src, globalSumInv, maxNum);
        __memcpy(destination + s * dimsize + repeat * maxNum, src, remain * sizeof(T), NRAM2GDRAM);
      }
    }
    
  }
  else{
    int multiple = maxNum / dimsize;//一个src可以处理multiple个otherIdx
    int size = taskDim * multiple;//所有core可以处理size个otherIdx
    int remain = othersize % size;// remain < taskDim * multiple
    int repeat = (othersize - remain) / size;

    int remainT = remain % taskDim;
    int stepEasy = (remain - remainT) / taskDim;
    int stepHard = stepEasy + 1;
    int step = (taskId < remainT ? stepHard : stepEasy);
    int startHard = taskId * stepHard * dimsize;//前面remainT个taskId分配到stepHard个dimsize
    int startEasy = remainT * stepHard * dimsize + (taskId - remainT) * stepEasy * dimsize;
    int indStart = (taskId < remainT ? startHard : startEasy);
    
    //-----------------------------------------allocate memory
    T* src = (T *)nram_buffer;//src[maxNum]
    T* tmp = src + 3 * maxNum;//tmp[dimS]
    T* destSum = tmp + dimS;//destSum[dimS],dimS >= max(dimsize, wSize), dimS = pow(2,K) ,pow(2,K - 1) < dimsize
    T* destSumFinal = destSum + wSize;
    //-----------------------------------------
    //printf("taskId:%d, repeat:%d, step:%d, repeatDim:%d, indstart:%d, %d\n", taskId, repeat, step, repeatDim, indStart, indStart * dimsize);
    int tid;
    __bang_write_value(tmp, dimS, -INFINITY);
    __bang_write_zero(destSum, dimS);
    if(repeat >= 2){
        int s = 0;
        tid = s * size * dimsize + taskId * multiple * dimsize;
        __memcpy(src + s % 3 * maxNum, source + tid, multiple * dimsize * sizeof(T), GDRAM2NRAM);
        s = 1;
        tid = s * size * dimsize + taskId * multiple * dimsize;
        __memcpy_async(src + s % 3 * maxNum, source + tid, multiple * dimsize * sizeof(T), GDRAM2NRAM);

        // compute ------------------------
        for(int j = 0; j < multiple; j++){
            
            __memcpy(tmp, src + (s - 1) %3 * maxNum + j * dimsize, dimsize * sizeof(T), NRAM2NRAM);
            __bang_argmax(srcMax, tmp, dimS);
            __bang_sub_scalar(tmp, tmp, srcMax[0], dimS);
            __memcpy(src + (s - 1) %3 * maxNum + j * dimsize, tmp, dimsize * sizeof(T), NRAM2NRAM);
        }
        __bang_active_exp_less_0(src + (s - 1) %3 * maxNum, src + (s - 1) %3 * maxNum, maxNum);
        for(int j = 0; j < multiple; j++){
            
            __memcpy(destSum, src + (s - 1) %3 * maxNum + j * dimsize, dimsize * sizeof(T), NRAM2NRAM);
            __memcpy(tmp, destSum, dimsize * sizeof(T), NRAM2NRAM);
            int segNum = dimS / wSize;//Starting numerical summation
            for(int strip = segNum/2; strip > 0; strip = strip / 2){
                for(int i = 0; i < strip ; i++){
                    __bang_add(destSum + i * wSize, destSum + i * wSize, destSum + (i + strip) * wSize, wSize);
                } 
            }
            __bang_reduce_sum(destSumFinal, destSum, wSize);
            T globalSumInv = 1.0/destSumFinal[0];
            __bang_mul_scalar(tmp, tmp, globalSumInv, dimS);

            __memcpy(src + (s - 1) %3 * maxNum + j * dimsize, tmp, dimsize * sizeof(T), NRAM2NRAM);
        }
        // compute ------------------------

        for(int s = 2; s < repeat; s++){
            tid = (s - 2) * size * dimsize + taskId * multiple * dimsize;
            __memcpy_async(destination + tid, src + (s - 2) % 3 * maxNum, multiple * dimsize * sizeof(T), NRAM2GDRAM);

            tid = s * size * dimsize + taskId * multiple * dimsize;
            __memcpy_async(src + s % 3 * maxNum, source + tid, multiple * dimsize * sizeof(T), GDRAM2NRAM);
            
            // compute ------------------------
            
            __bang_argmax(srcMax, src + (s - 1) %3 * maxNum, maxNum);//这一段特殊处理取全局max
            __bang_sub_scalar(src + (s - 1) %3 * maxNum, src + (s - 1) %3 * maxNum, srcMax[0], maxNum);
            __bang_active_exp_less_0(src + (s - 1) %3 * maxNum, src + (s - 1) %3 * maxNum, maxNum);
            
            for(int j = 0; j < multiple; j++){
                __memcpy(destSum, src + (s - 1) %3 * maxNum + j * dimsize, dimsize * sizeof(T), NRAM2NRAM);
                __memcpy(tmp, destSum, dimsize * sizeof(T), NRAM2NRAM);
                int segNum = dimS / wSize;//Starting numerical summation
                for(int strip = segNum/2; strip > 0; strip = strip / 2){
                    for(int i = 0; i < strip ; i++){
                        __bang_add(destSum + i * wSize, destSum + i * wSize, destSum + (i + strip) * wSize, wSize);
                    } 
                }
                __bang_reduce_sum(destSumFinal, destSum, wSize);
                T globalSumInv = 1.0/destSumFinal[0];
                __bang_mul_scalar(tmp, tmp, globalSumInv, dimS);

                __memcpy(src + (s - 1) %3 * maxNum + j * dimsize, tmp, dimsize * sizeof(T), NRAM2NRAM);
            }
            // compute ------------------------
        }
        s = repeat;
        tid = (s - 2) * size * dimsize + taskId * multiple * dimsize;
        __memcpy_async(destination + tid, src + (s - 2) % 3 * maxNum, multiple * dimsize * sizeof(T), NRAM2GDRAM);
        // compute ------------------------
        for(int j = 0; j < multiple; j++){
            
            __memcpy(tmp, src + (s - 1) %3 * maxNum + j * dimsize, dimsize * sizeof(T), NRAM2NRAM);
            __bang_argmax(srcMax, tmp, dimS);
            __bang_sub_scalar(tmp, tmp, srcMax[0], dimS);
            __memcpy(src + (s - 1) %3 * maxNum + j * dimsize, tmp, dimsize * sizeof(T), NRAM2NRAM);
        }
        __bang_active_exp_less_0(src + (s - 1) %3 * maxNum, src + (s - 1) %3 * maxNum, maxNum);
        for(int j = 0; j < multiple; j++){
            
            __memcpy(destSum, src + (s - 1) %3 * maxNum + j * dimsize, dimsize * sizeof(T), NRAM2NRAM);
            __memcpy(tmp, destSum, dimsize * sizeof(T), NRAM2NRAM);
            int segNum = dimS / wSize;//Starting numerical summation
            for(int strip = segNum/2; strip > 0; strip = strip / 2){
                for(int i = 0; i < strip ; i++){
                    __bang_add(destSum + i * wSize, destSum + i * wSize, destSum + (i + strip) * wSize, wSize);
                } 
            }
            __bang_reduce_sum(destSumFinal, destSum, wSize);
            T globalSumInv = 1.0/destSumFinal[0];
            __bang_mul_scalar(tmp, tmp, globalSumInv, dimS);

            __memcpy(src + (s - 1) %3 * maxNum + j * dimsize, tmp, dimsize * sizeof(T), NRAM2NRAM);
        }
        // compute ------------------------
        s = repeat + 1;
        tid = (s - 2) * size * dimsize + taskId * multiple * dimsize;
        __memcpy(destination + tid, src + (s - 2) % 3 * maxNum, multiple * dimsize * sizeof(T), NRAM2GDRAM);
    }
    else{
        for(int s = 0; s < repeat + 2; s++){
            if(s < repeat){
                tid = s * size * dimsize + taskId * multiple * dimsize;
                __memcpy_async(src + s % 3 * maxNum, source + tid, multiple * dimsize * sizeof(T), GDRAM2NRAM);
            }
            if(s > 0 && s < repeat + 1){
                // compute ------------------------
            
                for(int j = 0; j < multiple; j++){
                    __memcpy(tmp, src + (s - 1) %3 * maxNum + j * dimsize, dimsize * sizeof(T), NRAM2NRAM);
                    __bang_argmax(srcMax, tmp, dimS);
                    __bang_sub_scalar(tmp, tmp, srcMax[0], dimS);
                    __memcpy(src + (s - 1) %3 * maxNum + j * dimsize, tmp, dimsize * sizeof(T), NRAM2NRAM);
                }
                __bang_active_exp_less_0(src + (s - 1) %3 * maxNum, src + (s - 1) %3 * maxNum, maxNum);
                
                for(int j = 0; j < multiple; j++){
                    __memcpy(destSum, src + (s - 1) %3 * maxNum + j * dimsize, dimsize * sizeof(T), NRAM2NRAM);
                    __memcpy(tmp, destSum, dimsize * sizeof(T), NRAM2NRAM);
                    int segNum = dimS / wSize;//Starting numerical summation
                    for(int strip = segNum/2; strip > 0; strip = strip / 2){
                        for(int i = 0; i < strip ; i++){
                            __bang_add(destSum + i * wSize, destSum + i * wSize, destSum + (i + strip) * wSize, wSize);
                        } 
                    }
                    __bang_reduce_sum(destSumFinal, destSum, wSize);
                    T globalSumInv = 1.0/destSumFinal[0];
                    __bang_mul_scalar(tmp, tmp, globalSumInv, dimS);

                    __memcpy(src + (s - 1) %3 * maxNum + j * dimsize, tmp, dimsize * sizeof(T), NRAM2NRAM);
                }
                // compute ------------------------
            }
            if(s > 1){
                tid = (s - 2) * size * dimsize + taskId * multiple * dimsize;
                __memcpy_async(destination + tid, src + (s - 2) % 3 * maxNum, multiple * dimsize * sizeof(T), NRAM2GDRAM);
            }
            __sync_all_ipu();//如果maxNum比较小，此时访存时间＞计算时间，无法延迟
        }
    }
    if(step){
      tid = repeat * size * dimsize + indStart;
      __memcpy(src, source + tid, step * dimsize * sizeof(T), GDRAM2NRAM);
      for(int s = 0; s < step; s++){//Step targets parts of othersize that cannot be divided by multiple * dimsize
        __bang_write_zero(destSum, dimS);
        
        __bang_write_value(tmp, dimS, -INFINITY);
        __memcpy(tmp, src + s * dimsize, dimsize * sizeof(T), NRAM2NRAM);
        
        __bang_argmax(srcMax, tmp, dimS);
        
        __bang_sub_scalar(tmp, tmp, srcMax[0], dimS);
        
        __bang_active_exp_less_0(tmp, tmp, dimS);
        __memcpy(destSum, tmp, dimsize * sizeof(T), NRAM2NRAM);
        
        int segNum = dimS / wSize;
        for(int strip = segNum/2; strip > 0; strip = strip / 2){
          for(int i = 0; i < strip ; i++){
            __bang_add(destSum + i * wSize, destSum + i * wSize, destSum + (i + strip) * wSize, wSize);
          }
        }
        __bang_reduce_sum(destSumFinal, destSum, wSize);
        
        T globalSumInv = 1.0/destSumFinal[0];
        __bang_mul_scalar(tmp, tmp, globalSumInv, dimS);
        __memcpy(src + s * dimsize, tmp, dimsize * sizeof(T), NRAM2NRAM); 
      } 
      __memcpy(destination + tid, src, step * dimsize * sizeof(T), NRAM2GDRAM);
    }
    
  }
}
template<typename T>
__mlu_global__ void softmaxKernelAxis_s(T *destination, T const *source, T *tmpGdram, int othersize, int dimsize, int stride) {// axis = 0
  
  const int SRC_MAX_SIZE = NRAM_MAX_SIZE / 8;
  

  const int maxNum = SRC_MAX_SIZE/sizeof(T);
  if(othersize > taskDim * maxNum){
    //-----------------------------------------allocate memory
    T* src = (T *)nram_buffer;// src[3 * maxNum]
    T* tmpSum = src + 3 * maxNum;//tmpSum[maxNum]
    T* tmpNewMax = src + 4 * maxNum;//tmpNewMax[maxNum]
    T* tmpOldMax = src + 5 * maxNum;//tmpOldMax[maxNum]
    //-----------------------------------------
    int remain = othersize % taskDim;
    int stepEasy = (othersize - remain)/taskDim;
    int stepHard = stepEasy + 1;
    int step = (taskId < remain ? stepHard : stepEasy);//The first part of taskId handles an additional element
    int indStart = (taskId < remain ? taskId * stepHard : remain * stepHard + (taskId - remain) * stepEasy);
    int remainNram = step%maxNum;
    int repeat = (step - remainNram)/maxNum;
    
    for(int j = 0; j < repeat; j++){
      __bang_write_value(tmpNewMax, maxNum, -INFINITY);
      __bang_write_zero(tmpSum, maxNum);
      for(int i = 0; i < dimsize + 1; i++){
        if(i < dimsize){
          __memcpy_async(src + i % 2 * maxNum, source + i * stride + indStart + j * maxNum, maxNum * sizeof(T), GDRAM2NRAM);
        }
        if(i > 0){
          __bang_maxequal(tmpNewMax, tmpNewMax, src + (i - 1) % 2 * maxNum, maxNum);//Continuously updating the maximum value
          __bang_sub(src + (i - 1) % 2 * maxNum, src + (i - 1) % 2 * maxNum, tmpNewMax, maxNum);//x - M
          __bang_active_exp_less_0(src + (i - 1) % 2 * maxNum, src + (i - 1) % 2 * maxNum, maxNum);//exp(x - M)
          if(i > 1){
            __bang_sub(tmpOldMax, tmpOldMax, tmpNewMax, maxNum);//oldM = oldM - newM
            __bang_active_exp_less_0(tmpOldMax, tmpOldMax, maxNum);//exp(oldM - newM)
            __bang_mul(tmpSum, tmpSum, tmpOldMax, maxNum);//sum = sum * exp(oldM - newM)
          }
          __bang_add(tmpSum, tmpSum, src + (i - 1) % 2 * maxNum, maxNum);//sum += exp(x - M)
          __memcpy(tmpOldMax, tmpNewMax, maxNum * sizeof(T), NRAM2NRAM);//oldM = newM
        }
        __sync_all_ipu();
      } 
      __bang_active_reciphp(tmpSum, tmpSum, maxNum);//compute 1/sum
      
      for(int i = 0; i < dimsize + 2; i++){
        if(i < dimsize){
          __memcpy_async(src + i % 3 * maxNum, source + i * stride + indStart + j * maxNum, maxNum * sizeof(T), GDRAM2NRAM);
        }
        if(i > 0 && i < dimsize + 1){
          __bang_sub(src + (i - 1) % 3 * maxNum, src + (i - 1) % 3 * maxNum, tmpNewMax, maxNum);//x - M
          __bang_active_exp_less_0(src + (i - 1) % 3 * maxNum, src + (i - 1) % 3 * maxNum, maxNum);//exp(x - M)
          __bang_mul(src + (i - 1) % 3 * maxNum, src + (i - 1) % 3 * maxNum, tmpSum, maxNum);
        }
        if(i > 1){
          __memcpy_async(destination + (i - 2) * stride + indStart + j * maxNum, src + (i - 2) % 3 * maxNum, maxNum * sizeof(T), NRAM2GDRAM);
        }
        __sync_all_ipu();
      } 
    }
    if(remainNram){
      __bang_write_value(tmpNewMax, maxNum, -INFINITY);
      __bang_write_zero(tmpSum, maxNum);
      __bang_write_zero(src, 3 * maxNum);
      
      for(int i = 0; i < dimsize + 1; i++){
        if(i < dimsize){
          __memcpy_async(src + i % 2 * maxNum, source + i * stride + indStart + repeat * maxNum, remainNram * sizeof(T), GDRAM2NRAM);
        }
        if(i > 0){
          __bang_maxequal(tmpNewMax, tmpNewMax, src + (i - 1) % 2 * maxNum, maxNum);
          __bang_sub(src + (i - 1) % 2 * maxNum, src + (i - 1) % 2 * maxNum, tmpNewMax, maxNum);//x - M
          __bang_active_exp_less_0(src + (i - 1) % 2 * maxNum, src + (i - 1) % 2 * maxNum, maxNum);//exp(x - M)
          if(i > 1){
            __bang_sub(tmpOldMax, tmpOldMax, tmpNewMax, maxNum);//oldM = oldM - newM
            __bang_active_exp_less_0(tmpOldMax, tmpOldMax, maxNum);//exp(oldM - newM)
            __bang_mul(tmpSum, tmpSum, tmpOldMax, maxNum);      //sum = sum * exp(oldM - newM)
          }
          __bang_add(tmpSum, tmpSum, src + (i - 1) % 2 * maxNum, maxNum);//sum += exp(x - M)
          __memcpy(tmpOldMax, tmpNewMax, maxNum * sizeof(T), NRAM2NRAM);//oldM = newM
        }
        __sync_all_ipu();
      } 
      
      __bang_active_reciphp(tmpSum, tmpSum, maxNum);//compute 1/sum
      //Start exponential transformation and write back to GDRAM
      
      for(int i = 0; i < dimsize + 2; i++){
        if(i < dimsize){
          __memcpy_async(src + i % 3 * maxNum, source + i * stride + indStart + repeat * maxNum, remainNram * sizeof(T), GDRAM2NRAM);
        }
        if(i > 0 && i < dimsize + 1){
          __bang_sub(src + (i - 1) % 3 * maxNum, src + (i - 1) % 3 * maxNum, tmpNewMax, maxNum);//x - M
          __bang_active_exp_less_0(src + (i - 1) % 3 * maxNum, src + (i - 1) % 3 * maxNum, maxNum);//exp(x - M)
          __bang_mul(src + (i - 1) % 3 * maxNum, src + (i - 1) % 3 * maxNum, tmpSum, maxNum);
        }
        if(i > 1){
          __memcpy_async(destination + (i - 2) * stride + indStart + repeat * maxNum, src + (i - 2) % 3 * maxNum, remainNram * sizeof(T), NRAM2GDRAM);
        }
        __sync_all_ipu();
      }     
    }
  }
  else if (othersize > maxNum && othersize <= taskDim * maxNum){
    T* src = (T *)nram_buffer;// src[3 * maxNum]
    T* tmpSum = src + 3 * maxNum;//tmpSum[maxNum]
    T* tmpNewMax = src + 4 * maxNum;//tmpNewMax[maxNum]
    T* tmpOldMax = src + 5 * maxNum;//tmpOldMax[maxNum]
    //-----------------------------------------
    int remain = othersize % taskDim;
    int stepEasy = (othersize - remain)/taskDim;
    int stepHard = stepEasy + 1;
    int step = (taskId < remain ? stepHard : stepEasy);//The first part of taskId handles an additional element
    int indStart = (taskId < remain ? taskId * stepHard : remain * stepHard + (taskId - remain) * stepEasy);
    
    __bang_write_value(tmpNewMax, maxNum, -INFINITY);
    __bang_write_zero(tmpSum, maxNum);
    __bang_write_zero(src, 3 * maxNum);
    
    for(int i = 0; i < dimsize + 1; i++){
      if(i < dimsize){
        __memcpy_async(src + i % 2 * maxNum, source + i * stride + indStart, step * sizeof(T), GDRAM2NRAM);
      }
      if(i > 0){
        __bang_maxequal(tmpNewMax, tmpNewMax, src + (i - 1) % 2 * maxNum, maxNum);
        __bang_sub(src + (i - 1) % 2 * maxNum, src + (i - 1) % 2 * maxNum, tmpNewMax, maxNum);//x - M
        __bang_active_exp_less_0(src + (i - 1) % 2 * maxNum, src + (i - 1) % 2 * maxNum, maxNum);//exp(x - M)
        if(i > 1){
          __bang_sub(tmpOldMax, tmpOldMax, tmpNewMax, maxNum);//oldM = oldM - newM
          __bang_active_exp_less_0(tmpOldMax, tmpOldMax, maxNum);//exp(oldM - newM)
          __bang_mul(tmpSum, tmpSum, tmpOldMax, maxNum);      //sum = sum * exp(oldM - newM)
        }
        __bang_add(tmpSum, tmpSum, src + (i - 1) % 2 * maxNum, maxNum);//sum += exp(x - M)
        __memcpy(tmpOldMax, tmpNewMax, maxNum * sizeof(T), NRAM2NRAM);//oldM = newM
      }
      __sync_all_ipu();
    } 
    
    __bang_active_reciphp(tmpSum, tmpSum, maxNum);//compute 1/sum
    //Start exponential transformation and write back to GDRAM
    
    for(int i = 0; i < dimsize + 2; i++){
      if(i < dimsize){
        __memcpy_async(src + i % 3 * maxNum, source + i * stride + indStart, step * sizeof(T), GDRAM2NRAM);
      }
      if(i > 0 && i < dimsize + 1){
        __bang_sub(src + (i - 1) % 3 * maxNum, src + (i - 1) % 3 * maxNum, tmpNewMax, maxNum);//x - M
        __bang_active_exp_less_0(src + (i - 1) % 3 * maxNum, src + (i - 1) % 3 * maxNum, maxNum);//exp(x - M)
        __bang_mul(src + (i - 1) % 3 * maxNum, src + (i - 1) % 3 * maxNum, tmpSum, maxNum);
      }
      if(i > 1){
        __memcpy_async(destination + (i - 2) * stride + indStart, src + (i - 2) % 3 * maxNum, step * sizeof(T), NRAM2GDRAM);
      }
      __sync_all_ipu();
    }               
  }
  else{
    
    int multiple = maxNum / othersize;
    int size = taskDim * multiple;
    int remain = dimsize % size;
    int repeat = (dimsize - remain) / size;

    int remainT = remain % taskDim;
    int stepEasy = (remain - remainT) / taskDim;
    int stepHard = stepEasy + 1;
    int step = (taskId < remainT ? stepHard : stepEasy);
    int indStart = (taskId < remainT ? taskId * stepHard : remainT * stepHard + (taskId - remainT) * stepEasy);
    
    T* src = (T *)nram_buffer;// src[3 * maxNum]
    T* tmpSum = src + 3 * maxNum;//tmpSum[othersize]
    T* tmpNewMax = tmpSum + othersize;//tmpNewMax[othersize]
    T* tmpOldMax = tmpNewMax + othersize;//tmpOldMax[othersize]
    T* tmpGlobal = tmpOldMax + othersize;
    __bang_write_value(tmpNewMax, othersize, -INFINITY);
    
    __bang_write_zero(tmpSum, othersize);
    __bang_write_zero(src, 3 * maxNum);
    
    for(int i = 0; i < repeat + 1; i++){
      if (i < repeat){
        __memcpy_async(src + (i % 2) * maxNum, source + (i * size + taskId * multiple) * stride, multiple * othersize * sizeof(T), GDRAM2NRAM);//stride=othersize
      }
      if(i > 0){
        for(int m = 0; m < multiple; m++){
          __bang_maxequal(tmpNewMax, tmpNewMax, src + (i - 1) % 2 * maxNum + m * othersize, othersize);
        }
        for(int m = 0; m < multiple; m++){
          __bang_sub(src + (i - 1) % 2 * maxNum + m * othersize, src + (i - 1) % 2 * maxNum + m * othersize, tmpNewMax, othersize);//x - M
        }
        __bang_active_exp_less_0(src + (i - 1) % 2 * maxNum, src + (i - 1) % 2 * maxNum, multiple * othersize);//exp(x - M)
        if(i > 1){
          __bang_sub(tmpOldMax, tmpOldMax, tmpNewMax, othersize);//oldM = oldM - newM
          __bang_active_exp_less_0(tmpOldMax, tmpOldMax, othersize);//exp(oldM - newM)
          __bang_mul(tmpSum, tmpSum, tmpOldMax, othersize);      //sum = sum * exp(oldM - newM)
        }
        for(int m = 0; m < multiple; m++){
          __bang_add(tmpSum, tmpSum, src + (i - 1) % 2 * maxNum + m * othersize, othersize);
        }
        __memcpy(tmpOldMax, tmpNewMax, othersize * sizeof(T), NRAM2NRAM);
      }
      __sync_all_ipu();
    }
    
    if(step) {
      __memcpy(src, source + repeat * size * stride + indStart * stride, step * othersize * sizeof(T), GDRAM2NRAM);//stride=othersize
      
      for(int m = 0; m < step; m++){
        __bang_maxequal(tmpNewMax, tmpNewMax, src + m * othersize, othersize);
      }
      for(int m = 0; m < step; m++){
        __bang_sub(src + m * othersize, src + m * othersize, tmpNewMax, othersize);//x - M
      }
      __bang_active_exp_less_0(src, src, step * othersize);//exp(x - M)
      if(repeat > 0){
        __bang_sub(tmpOldMax, tmpOldMax, tmpNewMax, othersize);//oldM = oldM - newM
        __bang_active_exp_less_0(tmpOldMax, tmpOldMax, othersize);//exp(oldM - newM)
        __bang_mul(tmpSum, tmpSum, tmpOldMax, othersize);      //sum = sum * exp(oldM - newM)
      }
      for(int m = 0; m < step; m++){
        __bang_add(tmpSum, tmpSum, src + m * othersize, othersize);
      }
      __memcpy(tmpOldMax, tmpNewMax, othersize * sizeof(T), NRAM2NRAM);
    }
    //----------------
    if(repeat > 0 || dimsize >= taskDim){
      __memcpy(tmpGdram + taskId * othersize, tmpNewMax, othersize * sizeof(T), NRAM2GDRAM);
      __sync_all();
      __bang_write_value(tmpNewMax, othersize, -INFINITY);
      for(int id = 0; id < taskDim; id++){
        __memcpy(tmpGlobal, tmpGdram + id * othersize, othersize * sizeof(T), GDRAM2NRAM);
        __bang_maxequal(tmpNewMax, tmpNewMax, tmpGlobal, othersize);
      }
      __bang_sub(tmpOldMax, tmpOldMax, tmpNewMax, othersize);
      __bang_active_exp_less_0(tmpOldMax, tmpOldMax, othersize);
      __bang_mul(tmpSum, tmpSum, tmpOldMax, othersize);
      __memcpy(tmpGdram + taskId * othersize, tmpSum, othersize * sizeof(T), NRAM2GDRAM);
      __sync_all();
      __bang_write_zero(tmpSum, othersize);
      for(int id = 0; id < taskDim; id++){
        __memcpy(tmpGlobal, tmpGdram + id * othersize, othersize * sizeof(T), GDRAM2NRAM);
        __bang_add(tmpSum, tmpSum, tmpGlobal, othersize);
      }
      __bang_active_recip_greater_1(tmpSum, tmpSum, othersize);
    }
    else{
      __memcpy(tmpGdram + taskId * othersize, tmpNewMax, othersize * sizeof(T), NRAM2GDRAM);
      __sync_all();
      __bang_write_value(tmpNewMax, othersize, -INFINITY);
      for(int id = 0; id < dimsize; id++){
        __memcpy(tmpGlobal, tmpGdram + id * othersize, othersize * sizeof(T), GDRAM2NRAM);
        __bang_maxequal(tmpNewMax, tmpNewMax, tmpGlobal, othersize);
      }
      __bang_sub(tmpOldMax, tmpOldMax, tmpNewMax, othersize);
      __bang_active_exp_less_0(tmpOldMax, tmpOldMax, othersize);
      __bang_mul(tmpSum, tmpSum, tmpOldMax, othersize);
      __memcpy(tmpGdram + taskId * othersize, tmpSum, othersize * sizeof(T), NRAM2GDRAM);
      __sync_all();
      __bang_write_zero(tmpSum, othersize);
      for(int id = 0; id < dimsize; id++){
        __memcpy(tmpGlobal, tmpGdram + id * othersize, othersize * sizeof(T), GDRAM2NRAM);
        __bang_add(tmpSum, tmpSum, tmpGlobal, othersize);
      }
      __bang_active_recip_greater_1(tmpSum, tmpSum, othersize);
    }
    
    //-------------------
    for(int i = 0; i < repeat + 2; i++){
      if(i < repeat){
        __memcpy_async(src + (i % 3) * maxNum, source + (i * size + taskId * multiple) * stride, multiple * othersize * sizeof(T), GDRAM2NRAM);//stride=othersize
      }
      if(i > 0){
        for(int m = 0; m < multiple; m++){
          __bang_sub(src + (i - 1) % 3 * maxNum + m * othersize, src + (i - 1) % 3 * maxNum + m * othersize, tmpNewMax, othersize);
        }
        __bang_active_exp_less_0(src + (i - 1) % 3 * maxNum, src + (i - 1) % 3 * maxNum, multiple * othersize);
        for(int m = 0; m < multiple; m++){
          __bang_mul(src + (i - 1) % 3 * maxNum + m * othersize, src + (i - 1) % 3 * maxNum + m * othersize, tmpSum, othersize);
        }
      }
      if (i > 1){
        __memcpy_async(destination + ((i - 2) * size + taskId * multiple) * stride, src + (i - 2) % 3 * maxNum, multiple * othersize * sizeof(T), NRAM2GDRAM);
      }
      __sync_all_ipu();
    }
    if(step) {
      __memcpy(src, source + repeat * size * stride + indStart * stride, step * othersize * sizeof(T), GDRAM2NRAM);//stride=othersize
      for(int m = 0; m < step; m++){
        __bang_sub(src + m * othersize, src + m * othersize, tmpNewMax, othersize);
      }
      __bang_active_exp_less_0(src, src, step * othersize);
      for(int m = 0; m < step; m++){
        __bang_mul(src + m * othersize, src + m * othersize, tmpSum, othersize);
      }
      __memcpy(destination + repeat * size * stride + indStart * stride, src, step * othersize * sizeof(T), NRAM2GDRAM);
    }
  }
}
template<typename T>
__mlu_global__ void softmaxKernelAxis_m(T *destination, T const *source, int frontsize, int dimsize, int stride, int strideS) {
  // 0<axis<dim -1 
  
  const int SRC_MAX_SIZE = NRAM_MAX_SIZE / 8;
  
  const int maxNum = SRC_MAX_SIZE/sizeof(T);
  if(stride >= maxNum){
    //-----------------------------------------allocate memory
    T *src = (T *)nram_buffer;
    T *tmpSum = src + 3 * maxNum;
    T *tmpNewMax = tmpSum + maxNum;
    T *tmpOldMax = tmpNewMax + maxNum;
    //-----------------------------------------
    int remain = stride % maxNum;
    int repeat = (stride - remain) / maxNum;
    
    for(int ind = taskId; ind < frontsize; ind += taskDim){
      int frontIdx = ind * dimsize * stride;
      for(int j = 0; j < repeat; j++){
        __bang_write_value(tmpNewMax, maxNum, -INFINITY);
        __bang_write_zero(tmpSum, maxNum);
        //__bang_write_zero(src, maxNum);
        for(int i = 0; i < dimsize; i++){
          __memcpy(src, source + frontIdx + i * stride + j * maxNum, maxNum * sizeof(T), GDRAM2NRAM);
          __bang_maxequal(tmpNewMax, tmpNewMax, src, maxNum);//Continuously updating the maximum value
          __bang_sub(src, src, tmpNewMax, maxNum);//x - M
          __bang_active_exp_less_0(src, src, maxNum);//exp(x - M)
          if(i > 0){
            __bang_sub(tmpOldMax, tmpOldMax, tmpNewMax, maxNum);//oldM = oldM - newM
            __bang_active_exp_less_0(tmpOldMax, tmpOldMax, maxNum);//exp(oldM - newM)
            __bang_mul(tmpSum, tmpSum, tmpOldMax, maxNum);//sum = sum * exp(oldM - newM)
          }
          __bang_add(tmpSum, tmpSum, src, maxNum);//sum += exp(x - M)
          __memcpy(tmpOldMax, tmpNewMax, maxNum * sizeof(T), NRAM2NRAM);//oldM = newM
        }
        __bang_active_reciphp(tmpSum, tmpSum, maxNum);//计算1/sum
        //Start exponential transformation and write back to GDRAM
        __bang_mul(src, src, tmpSum, maxNum);//The data stored in the src at the end of the loop above can be utilized
        __memcpy(destination + (dimsize - 1) * stride + frontIdx + j * maxNum, src, maxNum * sizeof(T), NRAM2GDRAM);
        for(int i = 0; i < dimsize - 1; i++){
          __memcpy(src, source + frontIdx + i * stride + j * maxNum, maxNum * sizeof(T), GDRAM2NRAM);
          __bang_sub(src, src, tmpNewMax, maxNum);//x - M
          __bang_active_exp_less_0(src, src, maxNum);//exp(x - M)
          __bang_mul(src, src, tmpSum, maxNum);
          __memcpy(destination + frontIdx + i * stride + j * maxNum, src, maxNum * sizeof(T), NRAM2GDRAM);
        } 
      }
      if(remain){
        
        __bang_write_value(tmpNewMax, maxNum, -INFINITY);
        __bang_write_zero(tmpSum, maxNum);
        __bang_write_value(src, maxNum, -INFINITY);
        for(int i = 0; i < dimsize; i++){
          __memcpy(src, source + frontIdx + i * stride + repeat * maxNum, remain * sizeof(T), GDRAM2NRAM);
          __bang_maxequal(tmpNewMax, tmpNewMax, src, maxNum);
          __bang_sub(src, src, tmpNewMax, maxNum);//x - M
          __bang_active_exp_less_0(src, src, maxNum);//exp(x - M)
          if(i > 0){
            __bang_sub(tmpOldMax, tmpOldMax, tmpNewMax, maxNum);//oldM = oldM - newM
            __bang_active_exp_less_0(tmpOldMax, tmpOldMax, maxNum);//exp(oldM - newM)
            __bang_mul(tmpSum, tmpSum, tmpOldMax, maxNum);      //sum = sum * exp(oldM - newM)
          }
          __bang_add(tmpSum, tmpSum, src, maxNum);//sum += exp(x - M)
          __memcpy(tmpOldMax, tmpNewMax, maxNum * sizeof(T), NRAM2NRAM);//oldM = newM
        }
        //-------------------
        __bang_active_reciphp(tmpSum, tmpSum, maxNum);//计算1/sum
        //Start exponential transformation and write back to GDRAM
        __bang_mul(src, src, tmpSum, maxNum);//The data stored in the src at the end of the loop above can be utilized
        __memcpy(destination + (dimsize - 1) * stride + frontIdx + repeat * maxNum, src, remain * sizeof(T), NRAM2GDRAM);
        for(int i = 0; i < dimsize - 1; i++){
          __memcpy(src, source + i * stride + frontIdx + repeat * maxNum, remain * sizeof(T), GDRAM2NRAM);
          __bang_sub(src, src, tmpNewMax, maxNum);//x - M
          __bang_active_exp_less_0(src, src, maxNum);//exp(x - M)
          __bang_mul(src, src, tmpSum, maxNum);
          __memcpy(destination + i * stride + frontIdx + repeat * maxNum, src, remain * sizeof(T), NRAM2GDRAM);
        } 
        //---------------------
      }
    }
  }
  else if(stride < maxNum && dimsize * stride >= maxNum){
   
    //-----------------------------------------allocate memory
    T* src = (T *)nram_buffer;
    T* tmp = src + 3 * maxNum;
    T* tmpOldMax = tmp + strideS;
    T* tmpNewMax = tmpOldMax + strideS;
    T* tmpSum = tmpNewMax + strideS;
    //-----------------------------------------
    int multiple = maxNum / stride;
    int size = multiple * stride;//The maximum amount of data that can be stored in an SRC
    int remain = dimsize % multiple;//If it cannot be divisible, this part of the data needs special processing
    int repeat = (dimsize - remain) / multiple;//The total number of loops required to load the entire dimsize

    int taskRemain = frontsize % taskDim;
    int stepEasy = (frontsize - taskRemain) / taskDim;
    int stepHard = stepEasy + 1;
    int step = (taskId < taskRemain ? stepHard : stepEasy);//The number of frontsize processed per taskId
    int indStart = (taskId < taskRemain ? taskId * stepHard : taskRemain * stepHard + (taskId - taskRemain) * stepEasy);
    source = source + indStart * dimsize * stride;
    destination = destination + indStart * dimsize * stride;
    //printf("maxNum:%d, dimsize * stride:%d, multiple:%d, size:%d, repeat:%d,remain:%d\n",maxNum, dimsize * stride, multiple, size, repeat,remain);
    for(int ind = 0; ind < step; ind++){
      int frontIdx = ind * dimsize * stride;
      
      __bang_write_value(tmpNewMax, strideS, -INFINITY);//Must be initialized to negative infinity
      __bang_write_value(tmp, strideS, -INFINITY);//Must be initialized to negative infinity
      __bang_write_zero(tmpSum, strideS);//Must be initialized to zero
      
      for(int j = 0; j < repeat + 1; j++){
        if(j < repeat){
          __memcpy_async(src + j % 2 * maxNum, source + frontIdx + j * multiple * stride, size * sizeof(T), GDRAM2NRAM);
        }
        if(j > 0){
          for(int m = 0; m < multiple; m++){
            __memcpy(tmp, src + (j - 1) % 2 * maxNum + m * stride, stride * sizeof(T), NRAM2NRAM);
            
            __bang_maxequal(tmpNewMax, tmpNewMax, tmp, strideS);//Although the stream S stream section after tmpNewMax is 0, there is no need to write back to GDRAM, which does not affect the result
            
            __bang_sub(tmp, tmp, tmpNewMax, strideS);//The stripe S stripe section after tmp is 0
            __bang_active_exp_less_0(tmp, tmp, strideS);
            if(j != 1 || m != 0){
              __bang_sub(tmpOldMax, tmpOldMax, tmpNewMax, strideS);//oldM = oldM - newM
              __bang_active_exp_less_0(tmpOldMax, tmpOldMax, strideS);//exp(oldM - newM)
              __bang_mul(tmpSum, tmpSum, tmpOldMax, strideS);//sum = sum * exp(oldM - newM)
            }
            __bang_add(tmpSum, tmpSum, tmp, strideS);//sum += exp(x - M)
            
            __memcpy(tmpOldMax, tmpNewMax, stride * sizeof(T), NRAM2NRAM);//oldM = newM
          }
        }
        __sync_all_ipu();
      }
      
      if(remain){
        __memcpy(src, source + frontIdx + repeat * multiple * stride, remain * stride * sizeof(T), GDRAM2NRAM);
        for(int m = 0; m < remain; m++){
          __memcpy(tmp, src + m * stride, stride * sizeof(T), NRAM2NRAM);
          __bang_maxequal(tmpNewMax, tmpNewMax, tmp, strideS);
          __bang_sub(tmp, tmp, tmpNewMax, strideS);//The stripe S stripe section after tmp is 0
          __bang_active_exp_less_0(tmp, tmp, strideS);
          if(repeat != 0 || m != 0){
            __bang_sub(tmpOldMax, tmpOldMax, tmpNewMax, strideS);//oldM = oldM - newM
            __bang_active_exp_less_0(tmpOldMax, tmpOldMax, strideS);//exp(oldM - newM)
            __bang_mul(tmpSum, tmpSum, tmpOldMax, strideS);//sum = sum * exp(oldM - newM)
          }
          __bang_add(tmpSum, tmpSum, tmp, strideS);//sum += exp(x - M)
          __memcpy(tmpOldMax, tmpNewMax, stride * sizeof(T), NRAM2NRAM);//oldM = newM
        }
      }
      
      //At this point, tmpNewMax stores the maximum value of the data corresponding to a fixed frontIdx and bedsize, while tmpSum stores the corresponding value sum
      
      __bang_active_reciphp(tmpSum, tmpSum, strideS);
      
      if(remain){
        for(int m = 0; m < remain; m++){
          __memcpy(tmp, src + m * stride, stride * sizeof(T), NRAM2NRAM);
          __bang_sub(tmp, tmp, tmpNewMax, strideS);
          __bang_active_exp_less_0(tmp, tmp, strideS);
          __bang_mul(tmp, tmp, tmpSum, strideS);
          __memcpy(destination + frontIdx + repeat * multiple * stride + m * stride, tmp, stride * sizeof(T), NRAM2GDRAM);
        }
        
      }
      for(int j = 0 ; j < repeat + 2; j++){
        if(j < repeat){
          __memcpy_async(src + j % 3 * maxNum, source + frontIdx + j * multiple * stride, size * sizeof(T), GDRAM2NRAM);
        }
        if(j > 0 && j < repeat + 1){
          for(int m = 0; m < multiple; m++){
            __memcpy(tmp, src + (j - 1) % 3 * maxNum + m * stride, stride * sizeof(T), NRAM2NRAM);
            
            __bang_sub(tmp, tmp, tmpNewMax, strideS);
            __bang_active_exp_less_0(tmp, tmp, strideS);
            __bang_mul(tmp, tmp, tmpSum, strideS);
            __memcpy(src + (j - 1) % 3 * maxNum + m * stride, tmp, stride * sizeof(T), NRAM2NRAM);
          }
        }
        if(j > 1){
          __memcpy_async(destination + frontIdx + (j - 2) * multiple * stride, src + (j - 2) % 3 * maxNum, size * sizeof(T), NRAM2GDRAM);
        }
        __sync_all_ipu();
      }
    }
  }
  else if(dimsize * stride < maxNum){
    //-----------------------------------------allocate memory
    T* src = (T *)nram_buffer;
    T* tmp = src + 3 * maxNum;
    T* tmpOldMax = tmp + strideS;
    T* tmpNewMax = tmpOldMax + strideS;
    T* tmpSum = tmpNewMax + strideS;
    //-----------------------------------------
    int behindsize = dimsize * stride;
    int multiple = maxNum / behindsize;//Represents the amount that a maxNum can share in frontsize
    
    int remainF = frontsize % (taskDim * multiple);
    int remainT = remainF % taskDim;
    int stepEasy = (remainF - remainT) / taskDim;
    int stepHard = stepEasy + 1;
    int step = (taskId < remainT ? stepHard : stepEasy);
    int taskRepeat = (frontsize - remainF) / (taskDim * multiple);
    //At this point, corresponding to frontsize, the amount of data processed by each taskId is taskRepeat * multiple+step
    int startHard = taskId * (taskRepeat * multiple + stepHard);
    int startEasy = remainT * (taskRepeat * multiple + stepHard) + (taskId - remainT) * (taskRepeat * multiple + stepEasy);
    int indStart = (taskId < remainT ? startHard: startEasy);
    source = source + indStart * behindsize;//indStart * behindsize Indicates the offset corresponding to different taskIds
    destination = destination + indStart * behindsize;
    int tid;
    for(int s = 0; s < taskRepeat + 2; s++){
      if(s < taskRepeat){
        tid = s * multiple * behindsize;
        __memcpy_async(src + s % 3 * maxNum, source + tid, multiple * behindsize * sizeof(T), GDRAM2NRAM);
      }
      if(s > 0 && s < taskRepeat + 1){
        for(int m = 0; m < multiple; m++){
          __bang_write_zero(tmpSum, strideS);
          __bang_write_value(tmp, strideS, -INFINITY);
          __bang_write_value(tmpNewMax, strideS, -INFINITY);
          for(int i = 0; i < dimsize; i++){
            __memcpy(tmp, src + (s - 1) % 3 * maxNum + m * behindsize + i * stride, stride * sizeof(T), NRAM2NRAM);
            __bang_maxequal(tmpNewMax, tmpNewMax, tmp, strideS);
            __bang_sub(tmp, tmp, tmpNewMax, strideS);//x - M
            __bang_active_exp_less_0(tmp, tmp, strideS);//exp(x - M)
            if(i > 0){
              __bang_sub(tmpOldMax, tmpOldMax, tmpNewMax, strideS);//oldM = oldM - newM
              __bang_active_exp_less_0(tmpOldMax, tmpOldMax, strideS);//exp(oldM - newM)
              __bang_mul(tmpSum, tmpSum, tmpOldMax, strideS);      //sum = sum * exp(oldM - newM)
            }
            __bang_add(tmpSum, tmpSum, tmp, strideS);//sum += exp(x - M)
            __memcpy(tmpOldMax, tmpNewMax, stride * sizeof(T), NRAM2NRAM);//oldM = newM
          }
          __bang_active_reciphp(tmpSum, tmpSum, strideS);
          __bang_mul(tmp, tmp, tmpSum, strideS);//The data stored in tmp at the end of the loop above can be utilized
          
          __memcpy(src + (s - 1) % 3 * maxNum + m * behindsize + (dimsize - 1) * stride, tmp, stride * sizeof(T), NRAM2NRAM);
          for(int i = 0; i < dimsize - 1; i++){
            __memcpy(tmp, src + (s - 1) % 3 * maxNum + m * behindsize + i * stride, stride * sizeof(T), NRAM2NRAM);
            __bang_sub(tmp, tmp, tmpNewMax, strideS);//x - M
            __bang_active_exp_less_0(tmp, tmp, strideS);//exp(x - M)
            __bang_mul(tmp, tmp, tmpSum, strideS);
            
            __memcpy(src + (s - 1) % 3 * maxNum + m * behindsize + i * stride, tmp, stride * sizeof(T), NRAM2NRAM);
          }
        }
      }
      if(s > 1){
        tid = (s - 2) * multiple * behindsize;
        __memcpy_async(destination + tid, src + (s - 2) % 3 * maxNum, multiple * behindsize * sizeof(T), NRAM2GDRAM);
      }
      __sync_all_ipu();
    }
    //__bang_printf("taskId:%d, multiple:%d, taskRepeat:%d, step:%d, indStart:%d\n",taskId, multiple, taskRepeat, step, indStart * behindsize);
    if(step){
      tid = taskRepeat * multiple * behindsize; 
      __memcpy(src, source + tid, step * behindsize * sizeof(T), GDRAM2NRAM);
      for(int m = 0; m < step; m++){
        __bang_write_zero(tmpSum, strideS);
        __bang_write_value(tmp, strideS, -INFINITY);
        __bang_write_value(tmpNewMax, strideS, -INFINITY);
        for(int i = 0; i < dimsize; i++){
          __memcpy(tmp, src + m * behindsize + i * stride, stride * sizeof(T), NRAM2NRAM);
          __bang_maxequal(tmpNewMax, tmpNewMax, tmp, strideS);
          __bang_sub(tmp, tmp, tmpNewMax, strideS);//x - M
          __bang_active_exp_less_0(tmp, tmp, strideS);//exp(x - M)
          if(i > 0){
            __bang_sub(tmpOldMax, tmpOldMax, tmpNewMax, strideS);//oldM = oldM - newM
            __bang_active_exp_less_0(tmpOldMax, tmpOldMax, strideS);//exp(oldM - newM)
            __bang_mul(tmpSum, tmpSum, tmpOldMax, strideS);      //sum = sum * exp(oldM - newM)
          }
          __bang_add(tmpSum, tmpSum, tmp, strideS);//sum += exp(x - M)
          __memcpy(tmpOldMax, tmpNewMax, stride * sizeof(T), NRAM2NRAM);//oldM = newM
        }
        //__bang_printf("max:%.2f,%.2f, sum:%.2f,sum:%.2f\n", tmpNewMax[0], tmpNewMax[1], tmpSum[0], tmpSum[0]);
        __bang_active_reciphp(tmpSum, tmpSum, strideS);
        __bang_mul(tmp, tmp, tmpSum, strideS);//The data stored in tmp at the end of the loop above can be utilized
        //__memcpy(destination + tid + m * behindsize + (dimsize - 1) * stride, tmp, stride * sizeof(T), NRAM2GDRAM);
        __memcpy(src + m * behindsize + (dimsize - 1) * stride, tmp, stride * sizeof(T), NRAM2NRAM);
        for(int i = 0; i < dimsize - 1; i++){
          __memcpy(tmp, src + m * behindsize + i * stride, stride * sizeof(T), NRAM2NRAM);
          __bang_sub(tmp, tmp, tmpNewMax, strideS);//x - M
          __bang_active_exp_less_0(tmp, tmp, strideS);//exp(x - M)
          __bang_mul(tmp, tmp, tmpSum, strideS);
          //__memcpy(destination + tid + m * behindsize + i * stride, tmp, stride * sizeof(T), NRAM2GDRAM);
          __memcpy(src + m * behindsize + i * stride, tmp, stride * sizeof(T), NRAM2NRAM);
        }
      }
      __memcpy(destination + tid, src, step * behindsize * sizeof(T), NRAM2GDRAM);
    }
  }
    
}

template<typename T>
void softmaxUnion1(cnrtQueue_t queue, void const *input, void *output, int othersize, int dimsize, int frontsize, int stride, int axis, int ndim) {
    auto source = reinterpret_cast<const T *>(input);
    auto destination = reinterpret_cast<T *>(output);
    const int wSize = 128 / sizeof(T);

    cnrtDim3_t k_dim;
    cnrtFunctionType_t k_type;

    k_dim.x = 16;
    k_dim.y = 1;
    k_dim.z = 1;
    k_type = CNRT_FUNC_TYPE_UNION1;
    
    int taskNum = k_dim.x * k_dim.y * k_dim.z;

    if(axis == ndim - 1){
        int dimS;
        float mi = log2(dimsize);
        if (floor(mi) == mi)
        {
            dimS = dimsize;
        }
        else
        {
            dimS = static_cast<int>(pow(2, floor(mi) + 1));
        }
        if (dimS < wSize)
        {
            dimS = wSize;
        }
        softmaxKernelAxis_e<T><<<k_dim, k_type, queue>>>(destination, source, othersize, dimsize, dimS);
    }
    else if(axis == 0){
        T *tmpGdram;
        CNRT_CHECK(cnrtMalloc((void **)&tmpGdram, taskNum * othersize * sizeof(T)));
        softmaxKernelAxis_s<T><<<k_dim, k_type, queue>>>(destination, source, tmpGdram, othersize, dimsize, stride);
        cnrtFree(tmpGdram);
    }
    else{
        float mi = log2(stride);
        int strideS;
        if(floor(mi) == mi){
            strideS = stride;
        }
        else{
            strideS = static_cast<int>(pow(2,floor(mi) + 1));
        }
        softmaxKernelAxis_m<T><<<k_dim, k_type, queue>>>(destination, source, frontsize, dimsize, stride, strideS);
    }
        
    cnrtQueueSync(queue);
}



extern "C" void softmax_bang(void const *input, void *output, int othersize, int dimsize, int frontsize, int stride, int axis, int ndim, int byteSize) {
    cnrtQueue_t queue;
    CNRT_CHECK(cnrtSetDevice(0));
    CNRT_CHECK(cnrtQueueCreate(&queue));
    if (byteSize == 4)
    {
        softmaxUnion1<float>(queue, input, output, othersize, dimsize, frontsize, stride, axis, ndim);
    }
    else if (byteSize == 2)
    {
        softmaxUnion1<half>(queue, input, output, othersize, dimsize, frontsize, stride, axis, ndim);
    }
    
    CNRT_CHECK(cnrtQueueDestroy(queue));
}
